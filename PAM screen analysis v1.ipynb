{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAM Screen Analysis\n",
    "Version 1.0\n",
    "\n",
    "1.25.17\n",
    "\n",
    "Zhang lab\n",
    "\n",
    "Authors: Omar Abudayyeh and Jonathan Gootenberg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import math\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting for figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newparams = {'axes.labelsize': 16, 'axes.linewidth': .5, 'savefig.dpi': 300, \n",
    "#              'axes.labelcolor': 'k',\n",
    "             'axes.titlesize': 16,\n",
    "                  'lines.linewidth': 2, 'figure.figsize': (15, 12),\n",
    "                   'figure.subplot.wspace': 0.1,\n",
    "                   'figure.subplot.hspace': 0.2,\n",
    "                   'ytick.labelsize': 14, 'xtick.labelsize': 14,\n",
    "                   'ytick.major.pad': 3.5, 'xtick.major.pad': 3.5,\n",
    "                   'ytick.major.size':0, 'xtick.major.size': 0,\n",
    "                   'legend.fontsize': 12, 'legend.frameon': False, \n",
    "#                    'axes.grid': False,\n",
    "      #              'axes.titlesize': 10,\n",
    "                   'xtick.direction': 'out',\n",
    "                   'ytick.direction': 'out'\n",
    "      #              'legend.handlelength': 1.5\n",
    "                   }\n",
    "plt.rcParams.update(newparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = [\n",
    "]\n",
    "\n",
    "for i in range(1,85):\n",
    "    name = \"S%s.dict\" % str(i).zfill(4)\n",
    "    files.append(name) \n",
    "\n",
    "sample_names = [\"20-DR1287_Left_20\",\"20-DR1287_Left_60\",\"21-DR1312_Left_20\",\"21-DR1312_Left_60\",\"21-DR-1317_Left_20\",\"21-DR-1317_Left_60\",\"21-DR1312_Right_20\",\"21-DR1312_Right_60\",\"21-DR-1317_Right_20\",\"21-DR-1317_Right_60\",\"22-DR1288_Left_20\",\"22-DR1288_Left_60\",\"25-DR1288_Left_20\",\"25-DR1288_Left_60\",\"31-DR1289_Left_20\",\"31-DR1289_Left_60\",\"32-DR1290_Left_20\",\"32-DR1290_Left_60\",\"34-DR1290_Left_20\",\"34-DR1290_Left_60\",\"35-DR1290_Left_20\",\"35-DR1290_Left_60\",\"39a-DR1314_Left_20\",\"39a-DR1314_Left_60\",\"39a-DR1319_Left_20\",\"39a-DR1319_Left_60\",\"39a-DR1291_Left_20\",\"39a-DR1291_Left_60\",\"39a-DR1314_Right_20\",\"39a-DR1314_Right_60\",\"39a-DR1319_Right_20\",\"39a-DR1319_Right_60\",\"39a-DR1291_Right_20\",\"39a-DR1291_Right_60\",\"39b-DR1314_Left_20\",\"39b-DR1314_Left_60\",\"39b-DR1319_Left_20\",\"39b-DR1319_Left_60\",\"39b-DR1291_Left_20\",\"39b-DR1291_Left_60\",\"39b-DR1314_Right_20\",\"39b-DR1314_Right_60\",\"39b-DR1319_Right_20\",\"39b-DR1319_Right_60\",\"39b-DR1291_Right_20\",\"39b-DR1291_Right_60\",\"40-DR1292_Left_20\",\"40-DR1292_Left_60\",\"41-DR1315_Left_20\",\"41-DR1315_Left_60\",\"41-DR1320_Left_20\",\"41-DR1320_Left_60\",\"41-DR1315_Right_20\",\"41-DR1315_Right_60\",\"41-DR1320_Right_20\",\"41-DR1320_Right_60\",\"42-DR1316_Left_20\",\"42-DR1316_Left_60\",\"42-DR1321_Left_20\",\"42-DR1321_Left_60\",\"42-DR1316_Right_20\",\"42-DR1316_Right_60\",\"42-DR1321_Right_20\",\"42-DR1321_Right_60\",\"43-DR1293_Left_20\",\"43-DR1293_Left_60\",\"44-DR1294_Left_20\",\"44-DR1294_Left_60\",\"45-DR1295_Left_20\",\"45-DR1295_Left_60\",\"47-DR1296_Left_20\",\"47-DR1296_Left_60\",\"48-DR1292_Left_20\",\"48-DR1292_Left_60\",\"49-DRFn_Left_20\",\"49-DRFn_Left_60\",\"50-DR1288_Left_20\",\"50-DR1288_Left_60\",\"Fn-DRFn_Left_20\",\"Fn-DRFn_Left_60\",\"neg ctrl_Left_20\",\"neg ctrl_Left_60\",\"neg ctrl_Right_20\",\"neg ctrl_Right_60\"]\n",
    "\n",
    "controls = {\"L20\":80,\"L60\":81,\"R20\":82,\"R60\":83}\n",
    "\n",
    "control_idx = [\"L20\",\"L60\",\"L20\",\"L60\",\"L20\",\"L60\",\"R20\",\"R60\",\"R20\",\"R60\",\n",
    "              \"L20\",\"L60\",\"L20\",\"L60\",\"L20\",\"L60\",\"L20\",\"L60\",\"L20\",\"L60\",\n",
    "              \"L20\",\"L60\",\"L20\",\"L60\",\"L20\",\"L60\",\"L20\",\"L60\",\"R20\",\"R60\",\n",
    "              \"R20\",\"R60\",\"R20\",\"R60\",\"L20\",\"L60\",\"L20\",\"L60\",\"L20\",\"L60\",\n",
    "              \"R20\",\"R60\",\"R20\",\"R60\",\"R20\",\"R60\",\"L20\",\"L60\",\"L20\",\"L60\",\n",
    "              \"L20\",\"L60\",\"R20\",\"R60\",\"R20\",\"R60\",\"L20\",\"L60\",\"L20\",\"L60\",\n",
    "              \"R20\",\"R60\",\"R20\",\"R60\",\"L20\",\"L60\",\"L20\",\"L60\",\"L20\",\"L60\",\n",
    "              \"L20\",\"L60\",\"L20\",\"L60\",\"L20\",\"L60\",\"L20\",\"L60\",\"L20\",\"L60\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dicts = []\n",
    "for i in range(len(files)):\n",
    "    print files[i]\n",
    "    dicts.append(pickle.load(open(files[i],'rb')))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at library representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change dicts[0] to your input sample\n",
    "vsort = sorted(dicts[0].values())\n",
    "\n",
    "low = int(0.05*len(vsort))\n",
    "high = int(0.95*len(vsort))\n",
    "\n",
    "print high\n",
    "print low\n",
    "print vsort[high]\n",
    "print vsort[low]\n",
    "\n",
    "#want this ratio to be low like around 5-10\n",
    "print float(vsort[high]/vsort[low])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at general data features (Unique PAMs and total reads) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Unique PAM analysis\n",
    "width = 0.5\n",
    "\n",
    "ind = np.arange(len(dicts))\n",
    "\n",
    "total_PAMs = []\n",
    "for x in range(len(dicts)):\n",
    "    total_PAMs.append(len(dicts[x]))\n",
    "\n",
    "\n",
    "plt.bar(ind,total_PAMs,width)\n",
    "plt.ylabel('# of Unique PAMs')\n",
    "plt.title(\"Unique PAMs Across Samples\")\n",
    "plt.xticks(ind+width/2,sample_names[0:-1],rotation=45 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#total number of reads\n",
    "\n",
    "width = 0.5\n",
    "N = len(dicts)\n",
    "ind = np.arange(N)\n",
    "\n",
    "reads = []\n",
    "for i in range(N):\n",
    "    reads.append(sum(dicts[i].values()))\n",
    "\n",
    "plt.bar(ind,reads,width)\n",
    "plt.ylabel('# of Reads')\n",
    "plt.title(\"Total Reads Across Samples\")\n",
    "plt.xticks(ind+width/2,sample_names[0:-1],rotation=45 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_reads = []\n",
    "for i in range(len(dicts)):\n",
    "    all_reads.append(sum(dicts[i].values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at frequency distributions of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dicts)):\n",
    "    counts = dicts[i].values()\n",
    "    counts.sort()\n",
    "    #print counts\n",
    "    ind = np.arange(len(counts))\n",
    "    #plt.subplot(4, 3, i+1)\n",
    "    plt.vlines(ind,0,counts)\n",
    "    plt.ylabel('# of Reads')\n",
    "    plt.title(\"Frequency Distribution of PAM for \"+sample_names[i])\n",
    "    #plt.xticks(ind+width/2,sample_names,rotation=45 )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating fold enrichment with pseudocounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratios = []\n",
    "\n",
    "for x in range(len(control_idx)):\n",
    "    #t is targeting samples\n",
    "    t = x\n",
    "    \n",
    "    #nt is the non-targeting control\n",
    "    nt = controls[control_idx[x]]    \n",
    "    pam_dict = {}\n",
    "    pams = set(dicts[t].keys()+dicts[nt].keys())\n",
    "    for pam in pams:\n",
    "        pam_dict[pam] = (-np.log2(((dicts[t][pam]+1.0)/reads[t])/((dicts[nt][pam]+1.0)/reads[nt])))\n",
    "    ratios.append(pam_dict)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Plotting fold enrichment distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(ratios)):\n",
    "    print i\n",
    "    ratios_sorted = ratios[i].values()\n",
    "    ratios_sorted.sort()\n",
    "    ind = np.arange(len(ratios_sorted))\n",
    "    plt.figure(i+1)\n",
    "    plt.vlines(ind,0,ratios_sorted)\n",
    "    plt.ylabel('-log2(Targeting/non-targeting)',fontsize=40)\n",
    "    #plt.ylim([-1.5,1.5])\n",
    "    plt.tick_params(axis='both', which='major', labelsize=30)\n",
    "    plt.title(\"Enrichment for \"+sample_names[i])\n",
    "    #plt.xticks(ind+width/2,sample_names,rotation=45 )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting top enriched PAMs above given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "all_pams = []\n",
    "#cutoff of 2 for Left PAM\n",
    "for i in range(len(ratios)):\n",
    "    all_pams.append([k for k,v in ratios[i].items() if v >2])\n",
    "    print len(all_pams[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating web logo motif for top enriched PAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for k in range(len(ratios)):\n",
    "    with open('{}.csv'.format(\"S\"+str(k)),'w') as out_file:\n",
    "        out_file.write('\\n'.join(all_pams[k]))\n",
    " \n",
    "for k in range(len(ratios)):\n",
    "    output = 'weblogo --format PDF --resolution 600 -c classic -P new_{}_{} '.format(sample_names[k],len(all_pams[k])) + '< {}.csv > '.format(\"S\"+str(k)) + ' new_{}.pdf '.format(\"S\"+str(k))\n",
    "    os.system(output)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Generating krona plots as html files for top enriched PAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_ratios_krona = []\n",
    "left_names_krona = []\n",
    "\n",
    "for x in range(len(control_idx)):\n",
    "    t = x\n",
    "    nt = controls[control_idx[x]]    \n",
    "    pam_dict = {}\n",
    "    pams = set(dicts[t].keys()+dicts[nt].keys())\n",
    "    for pam in pams:\n",
    "        pam_dict[pam] = (((dicts[t][pam]+1)/reads[t])/((dicts[nt][pam]+1)/reads[nt]))\n",
    "    left_ratios_krona.append(pam_dict)\n",
    "    left_names_krona.append(sample_names[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(left_ratios_krona)):\n",
    "    with open('{}.txt'.format(left_names_krona[i]),'w') as out_file:\n",
    "            for k,v in left_ratios_krona[i].items():\n",
    "                out_file.write('{}\\t{}\\n'.format(1/v,'\\t'.join(list(k[2:]))))\n",
    "cd_file_names = ['{}.txt,{}'.format(i,i) for i in left_names_krona]\n",
    "output = 'ktImportText {}'.format(' '.join(cd_file_names))\n",
    "os.system(output)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
